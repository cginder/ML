## Week 1 Question 2 HW
# install.packages("rpart.plot")

library(proxy)
library(rpart)      # package for trees
library(rpart.plot) # package that enhances plotting capabilities for rpart


## load cvknn library
download.file("https://raw.githubusercontent.com/ChicagoBoothML/HelpR/master/docv.R", "docv.R")
source("docv.R")

set.seed(99)

# download file (URL provided in HW Assignment)
download.file("https://raw.githubusercontent.com/ChicagoBoothML/MLClassData/master/UsedCars/UsedCars.csv",destfile = "UsedCars.csv")

# read file into R
Used.Cars <- read.csv("UsedCars.csv")

# explore header of file
head(Used.Cars)


############ 
# Question 2.1 
# Take a look at the data-set and describe for what kind of business related problems you could use this
# data. That is, why would anyone care to collect this data?
############

#### 2.2 - Split data into two parts: training set consisting of 75%, test set consisting of 25%

# get number of train samples that need to be drawn (75% * number of obs, rounded to nearest int)
ntrain <- round(.75*nrow(Used.Cars))

# pull random sample
tr <- sample(1:nrow(Used.Cars),ntrain)
df.train <- Used.Cars[tr,] # training data
df.test <- Used.Cars[-tr,] # test data

#### 2.3 -  Using ordinary linear regression, find a relationship between price and mileage of the form price = bo + b1 x mileage + e
car.lm <- lm(price~mileage, data = df.train)
summary(car.lm)
plot(price~mileage, data = df.train, cex = 0.6) # plot scatter plot, cex command controls dot size to make them smaller
abline(car.lm, col = "blue",lwd = 3, lty = "dashed") # plot the regression line

#### 2.4 - Fit polynomial regression to see if its a better fit. Equation: price = b0 + b1 x mileage + b2 x mileage^2 ... + bd x mileage^d + e
set.seed(99)

# test possible polynomial values 
dvec <- 1:10 # vector for possible polynomial terms
nd <- length(dvec) # total number of polynomial terms tried

dfolds <- 1:10
nfolds <- length(dfolds) # number of folds for CV
fold <- sample(nfolds, nrow(df.train), replace = TRUE)

outMSE <- rep(0,nd) #will will put the average out-of-sample MSE here for each d
foldMSE <- rep(0,nfolds) # for calculating each fold's MSE


for(i in 1:nd) {     # cycle on all possible d polynomial terms
  for (j in 1:nfolds) {  # rerun on number of folds
    take <- fold == j   
    foldj <- df.train[take,]
    foldOther <- df.train[!take,]
    
    poly <- lm(price ~ poly(mileage,i),data=foldOther) 
    pred <- predict(poly,foldj)
    foldMSE[j] <- mean((pred - foldj$price)^2)
    
  }
  outMSE[i] = mean(foldMSE)
}
imin = which.min(outMSE)
cat("best k is ",dvec[imin],"\n")
plot(dvec,outMSE)

# refit polynomial on all training data
# sort data to plot polynomial fitted values in order
poly.data <- df.train[order(df.train$mileage),]

# retrain final model on best polynomial term as determined above
finalpoly <- lm(price ~ poly(mileage,imin),data = poly.data)


# replot scatter
plot(price~mileage, data = df.train, cex = 0.6) # plot scatter plot, cex command controls dot size to make them smaller

# add polynomial line  **** may have to redo this to make it not jagged out on extremities (something like predict over the range 1:max(mileage))
lines(fitted(finalpoly)~ poly.data$mileage, col = "green" , lwd = 3)



#### Question 2.5.1 KNN
kv =seq(from = 2, to = 750, by = 20); nk=length(kv)

cars.cv = docvknn(matrix(df.train$mileage,ncol=1),df.train$price,kv,nfold=5)

# convert to MSE (docvknn returns error sum of squares)
cars.cv <- sqrt(cars.cv/length(df.train$mileage))

plot(log(1/kv),cars.cv,type = "l",col="red",lwd = 2,cex.lab = 1.0,xlab = "log(1/k)",ylab = "MSE")
imin = which.min(cars.cv)
cat("best k is ",kv[imin],"\n")

# refit model with all training data
kfbest = kknn(price~mileage,df.train,data.frame(mileage = sort(df.train$mileage)),k=kv[imin],kernel = "rectangular")

#### Question 2.5.2 Regression Tree

# create a big tree
cars.tree <- rpart(price~mileage,data = df.train, control = rpart.control(minsplit = 5,cp=0.0001,xval=5))

# stats on big tree
nbig <- length(unique(cars.tree$where))
cat("size of big tree ",nbig,"\n")

# print table of cross validation output
(cptable = printcp(cars.tree))
(bestcp = cptable[which.min(cptable[,"xerror"]),"CP"])  #find the optimal cp (smallest value of xerror)

plotcp(cars.tree) # plot results

# prune tree
best.tree <- prune(cars.tree,cp=bestcp)

rpart.plot(best.tree)

#### Questions 2.5.3 Scatter plot of price vs mileage with 3 models
plot(price ~ mileage, data = df.train)

# poly plot
lines(fitted(finalpoly)~ poly.data$mileage, col = "green" , lwd = 3)

# KNN plot
lines(sort(df.train$mileage),kfbest$fitted,col="red",lwd=2,cex.lab=2)


# trees plot
pfit <- predict(best.tree)
lines(sort(df.train$mileage),pfit,col="red",lwd=2,cex.lab=2)

